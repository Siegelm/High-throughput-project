{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GTF.py\n",
    "Kamil Slowikowski\n",
    "December 24, 2013\n",
    "Read GFF/GTF files. Works with gzip compressed files and pandas.\n",
    "    http://useast.ensembl.org/info/website/upload/gff.html\n",
    "LICENSE\n",
    "This is free and unencumbered software released into the public domain.\n",
    "Anyone is free to copy, modify, publish, use, compile, sell, or\n",
    "distribute this software, either in source code form or as a compiled\n",
    "binary, for any purpose, commercial or non-commercial, and by any\n",
    "means.\n",
    "In jurisdictions that recognize copyright laws, the author or authors\n",
    "of this software dedicate any and all copyright interest in the\n",
    "software to the public domain. We make this dedication for the benefit\n",
    "of the public at large and to the detriment of our heirs and\n",
    "successors. We intend this dedication to be an overt act of\n",
    "relinquishment in perpetuity of all present and future rights to this\n",
    "software under copyright law.\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    "EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n",
    "IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR\n",
    "OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\n",
    "ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n",
    "OTHER DEALINGS IN THE SOFTWARE.\n",
    "For more information, please refer to <http://unlicense.org/>\n",
    "\"\"\"\n",
    "from collections import defaultdict\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "\n",
    "\n",
    "GTF_HEADER  = ['seqname', 'source', 'feature', 'start', 'end', 'score',\n",
    "               'strand', 'frame']\n",
    "R_SEMICOLON = re.compile(r'\\s*;\\s*')\n",
    "R_COMMA     = re.compile(r'\\s*,\\s*')\n",
    "R_KEYVALUE  = re.compile(r'(\\s+|\\s*=\\s*)')\n",
    "\n",
    "\n",
    "def dataframe(filename):\n",
    "    \"\"\"Open an optionally gzipped GTF file and return a pandas.DataFrame.\n",
    "    \"\"\"\n",
    "    # Each column is a list stored as a value in this dict.\n",
    "    result = defaultdict(list)\n",
    "\n",
    "    for i, line in enumerate(lines(filename)):\n",
    "        for key in line.keys():\n",
    "            # This key has not been seen yet, so set it to None for all\n",
    "            # previous lines.\n",
    "            if key not in result:\n",
    "                result[key] = [None] * i\n",
    "\n",
    "        # Ensure this row has some value for each column.\n",
    "        for key in result.keys():\n",
    "            result[key].append(line.get(key, None))\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "def lines(filename):\n",
    "    \"\"\"Open an optionally gzipped GTF file and generate a dict for each line.\n",
    "    \"\"\"\n",
    "    fn_open = gzip.open if filename.endswith('.gz') else open\n",
    "\n",
    "    with fn_open(filename) as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            else:\n",
    "                yield parse(line)\n",
    "\n",
    "\n",
    "def parse(line):\n",
    "    \"\"\"Parse a single GTF line and return a dict.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "\n",
    "    fields = line.rstrip().split('\\t')\n",
    "\n",
    "    for i, col in enumerate(GTF_HEADER):\n",
    "        result[col] = _get_value(fields[i])\n",
    "\n",
    "    # INFO field consists of \"key1=value;key2=value;...\".\n",
    "    infos = [x for x in re.split(R_SEMICOLON, fields[8]) if x.strip()]\n",
    "\n",
    "    for i, info in enumerate(infos, 1):\n",
    "        # It should be key=\"value\".\n",
    "        try:\n",
    "            key, _, value = re.split(R_KEYVALUE, info, 1)\n",
    "        # But sometimes it is just \"value\".\n",
    "        except ValueError:\n",
    "            key = 'INFO{}'.format(i)\n",
    "            value = info\n",
    "        # Ignore the field if there is no value.\n",
    "        if value:\n",
    "            result[key] = _get_value(value)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def _get_value(value):\n",
    "    if not value:\n",
    "        return None\n",
    "\n",
    "    # Strip double and single quotes.\n",
    "    value = value.strip('\"\\'')\n",
    "\n",
    "    # Return a list if the value has a comma.\n",
    "    if ',' in value:\n",
    "        value = re.split(R_COMMA, value)\n",
    "    # These values are equivalent to None.\n",
    "    elif value in ['', '.', 'NA']:\n",
    "        return None\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the GFT file into a GCT file with all the 'Late' conditions\n",
    "Raw_Data=['66.gtf','29.gtf','58.gtf','18.gtf','35.gtf','21.gtf','89.gtf','87.gtf','95.gtf','97.gtf','76.gtf','77.gtf']\n",
    "Data=[]\n",
    "for i in range(len(Raw_Data)): #Convert and add each GTF file to a panda DataFrame\n",
    "    Data.append(dataframe(Raw_Data[i])) #Use GTF.py describe above to convert the GTF file into a panda DataFrame\n",
    "    Data[i]=Data[i][(Data[i].feature=='transcript')] #Keep only tge lines referring to a transcript\n",
    "    Data[i]=Data[i].drop(['seqname', 'source','feature', 'start', 'end', 'score', 'strand', 'frame', 'transcript_id','reference_id', 'cov', 'TPM', 'exon_number', 'gene_id', 'ref_gene_name'], axis=1)\n",
    "    #Delete all the columns exept the Gene ID and its relative expression\n",
    "    Data[i]=Data[i].loc[:,['ref_gene_id','FPKM']] #Reorganize the columns \n",
    "    Data[i]=Data[i].rename(columns={'ref_gene_id': 'NAME'}) #Rename the columns containing the gene ID \n",
    "    Data[i]=Data[i].dropna(subset=['NAME']) #Delete the rows without a gene ID\n",
    "    Data[i]=Data[i].drop_duplicates(subset='NAME',keep='first') #Onnly keep the first expression value for a gene ID\n",
    "    Data[i]=Data[i].rename(columns={'FPKM': Raw_Data[i]}) #Change the name of the column containing the expression value \n",
    "    #to have the information about the condition \n",
    "    Data[i]=Data[i].set_index('NAME') #Set the Gene ID as the index to allow the concatenation of the different DataFrame\n",
    "    #based on the gene ID\n",
    "Final=pd.concat(Data, axis=1) #Merge the list of DataFrame to a final DataFrame containg all conditions\n",
    "Final.to_csv(\"Late.txt\", sep=\"\\t\", quoting=csv.QUOTE_NONE) #Save the file in a tab delimited .xt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the GFT file into a GCT file with all the 'Early' conditions\n",
    "Raw_Data=['536.gtf','484.gtf','519.gtf','522.gtf','608.gtf','614.gtf','512.gtf','505.gtf','461.gtf','623.gtf','583.gtf','581.gtf']\n",
    "Data=[]\n",
    "for i in range(len(Raw_Data)):\n",
    "    Data.append(dataframe(Raw_Data[i]))\n",
    "    Data[i]=Data[i][(Data[i].feature=='transcript')]\n",
    "    Data[i]=Data[i].drop(['seqname', 'source','feature', 'start', 'end', 'score', 'strand', 'frame', 'transcript_id','reference_id', 'cov', 'TPM', 'exon_number', 'gene_id', 'ref_gene_name'], axis=1)\n",
    "    Data[i]=Data[i].loc[:,['ref_gene_id','FPKM']]\n",
    "    Data[i]=Data[i].rename(columns={'ref_gene_id': 'NAME'})\n",
    "    Data[i]=Data[i].dropna(subset=['NAME'])\n",
    "    Data[i]=Data[i].drop_duplicates(subset='NAME',keep='first')\n",
    "    Data[i]=Data[i].rename(columns={'FPKM': Raw_Data[i]})\n",
    "    Data[i]=Data[i].set_index('NAME')\n",
    "Final=pd.concat(Data, axis=1)\n",
    "Final.to_csv(\"Early.txt\", sep=\"\\t\", quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the GFT file into a GCT file with all the extracted 'Cells' conditions\n",
    "Raw_Data=['CtrlA.gtf','CtrlB.gtf','sh1A.gtf','sh1C.gtf','sh2A.gtf','sh2B.gtf']\n",
    "Data=[]\n",
    "for i in range(len(Raw_Data)):\n",
    "    Data.append(dataframe(Raw_Data[i]))\n",
    "    Data[i]=Data[i][(Data[i].feature=='transcript')]\n",
    "    Data[i]=Data[i].drop(['seqname', 'source','feature', 'start', 'end', 'score', 'strand', 'frame', 'transcript_id','reference_id', 'cov', 'TPM', 'exon_number', 'gene_id', 'ref_gene_name'], axis=1)\n",
    "    Data[i]=Data[i].loc[:,['ref_gene_id','FPKM']]\n",
    "    Data[i]=Data[i].rename(columns={'ref_gene_id': 'NAME'})\n",
    "    Data[i]=Data[i].dropna(subset=['NAME'])\n",
    "    Data[i]=Data[i].drop_duplicates(subset='NAME',keep='first')\n",
    "    Data[i]=Data[i].rename(columns={'FPKM': Raw_Data[i]})\n",
    "    Data[i]=Data[i].set_index('NAME')\n",
    "Final=pd.concat(Data, axis=1)\n",
    "Final.to_csv(\"Cells.txt\", sep=\"\\t\", quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
